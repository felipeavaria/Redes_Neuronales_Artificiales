{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta 3:\n",
    "## Predicción del Precio de una Casa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null int64\n",
      "CHAS       506 non-null int64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null int64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "MEDV       506 non-null float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.4 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11136.778656</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6860.352941</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9690.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27740.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN         INDUS        CHAS         NOX  \\\n",
       "count  506.000000  506.000000    506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636  11136.778656    0.069170    0.554695   \n",
       "std      8.601545   23.322453   6860.352941    0.253994    0.115878   \n",
       "min      0.006320    0.000000    460.000000    0.000000    0.385000   \n",
       "25%      0.082045    0.000000   5190.000000    0.000000    0.449000   \n",
       "50%      0.256510    0.000000   9690.000000    0.000000    0.538000   \n",
       "75%      3.677082   12.500000  18100.000000    0.000000    0.624000   \n",
       "max     88.976200  100.000000  27740.000000    1.000000    0.871000   \n",
       "\n",
       "               RM         AGE         DIS         RAD         TAX     PTRATIO  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     6.284634   68.574901    3.795043    9.549407  408.237154   18.455534   \n",
       "std      0.702617   28.148861    2.105710    8.707259  168.537116    2.164946   \n",
       "min      3.561000    2.900000    1.129600    1.000000  187.000000   12.600000   \n",
       "25%      5.885500   45.025000    2.100175    4.000000  279.000000   17.400000   \n",
       "50%      6.208500   77.500000    3.207450    5.000000  330.000000   19.050000   \n",
       "75%      6.623500   94.075000    5.188425   24.000000  666.000000   20.200000   \n",
       "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000   \n",
       "\n",
       "                B       LSTAT        MEDV  \n",
       "count  506.000000  506.000000  506.000000  \n",
       "mean   356.674032   12.653063   22.532806  \n",
       "std     91.294864    7.141062    9.197104  \n",
       "min      0.320000    1.730000    5.000000  \n",
       "25%    375.377500    6.950000   17.025000  \n",
       "50%    391.440000   11.360000   21.200000  \n",
       "75%    396.225000   16.955000   25.000000  \n",
       "max    396.900000   37.970000   50.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Archivo CSV\n",
    "url = 'DatasetCasa.csv'\n",
    "#lectura\n",
    "df = pd.read_csv(url, sep=' ',header=None, names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX',\n",
    "'RM', 'AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV'])\n",
    "#separación entre datos de entrenemiento y datos de prueba\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# 25% datos de prueba\n",
    "df_train,df_test= train_test_split(df,test_size=0.25, random_state=0) \n",
    "# status df\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(df_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(df_train),columns=df_train.columns)\n",
    "scaler = StandardScaler().fit(df_test)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(df_test),columns=df_test.columns)\n",
    "\n",
    "y_train = df_train.pop('MEDV')\n",
    "y_test = df_test.pop('MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/.local/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, kernel_initializer=\"uniform\", input_dim=14)`\n",
      "  \n",
      "/home/felipe/.local/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/300\n",
      "379/379 [==============================] - 0s - loss: 98.0075 - val_loss: 42.4746\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 0s - loss: 29.6781 - val_loss: 34.6792\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 0s - loss: 21.5241 - val_loss: 27.1395\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 0s - loss: 16.8943 - val_loss: 23.2646\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 0s - loss: 14.4737 - val_loss: 19.6290\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 0s - loss: 12.2472 - val_loss: 17.1638\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 0s - loss: 10.7770 - val_loss: 15.8200\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 0s - loss: 9.5528 - val_loss: 13.5488\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 0s - loss: 8.6174 - val_loss: 13.0947\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 0s - loss: 8.1150 - val_loss: 11.5177\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 0s - loss: 7.7117 - val_loss: 10.1383\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 0s - loss: 7.4822 - val_loss: 9.3514\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 0s - loss: 6.2694 - val_loss: 8.6254\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 0s - loss: 5.8272 - val_loss: 7.6697\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 0s - loss: 5.4586 - val_loss: 7.0480\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 0s - loss: 4.9665 - val_loss: 6.4952\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 0s - loss: 4.8025 - val_loss: 6.2578\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 0s - loss: 4.2577 - val_loss: 5.7491\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 0s - loss: 4.0172 - val_loss: 4.9880\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 0s - loss: 3.8108 - val_loss: 4.8100\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 0s - loss: 3.5709 - val_loss: 4.1619\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 0s - loss: 3.0141 - val_loss: 3.8623\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 0s - loss: 2.8052 - val_loss: 3.7677\n",
      "Epoch 24/300\n",
      "379/379 [==============================] - 0s - loss: 2.7064 - val_loss: 3.1046\n",
      "Epoch 25/300\n",
      "379/379 [==============================] - 0s - loss: 2.4621 - val_loss: 2.9247\n",
      "Epoch 26/300\n",
      "379/379 [==============================] - 0s - loss: 2.1160 - val_loss: 2.5824\n",
      "Epoch 27/300\n",
      "379/379 [==============================] - 0s - loss: 2.0090 - val_loss: 2.3907\n",
      "Epoch 28/300\n",
      "379/379 [==============================] - 0s - loss: 1.8083 - val_loss: 2.1246\n",
      "Epoch 29/300\n",
      "379/379 [==============================] - 0s - loss: 1.5897 - val_loss: 1.8927\n",
      "Epoch 30/300\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.051 - 0s - loss: 1.4714 - val_loss: 1.7068\n",
      "Epoch 31/300\n",
      "379/379 [==============================] - 0s - loss: 1.4150 - val_loss: 1.7204\n",
      "Epoch 32/300\n",
      "379/379 [==============================] - 0s - loss: 1.2735 - val_loss: 1.3998\n",
      "Epoch 33/300\n",
      "379/379 [==============================] - 0s - loss: 1.1940 - val_loss: 1.3663\n",
      "Epoch 34/300\n",
      "379/379 [==============================] - 0s - loss: 1.0368 - val_loss: 1.4257\n",
      "Epoch 35/300\n",
      "379/379 [==============================] - 0s - loss: 0.9592 - val_loss: 1.0219\n",
      "Epoch 36/300\n",
      "379/379 [==============================] - 0s - loss: 0.8718 - val_loss: 0.9478\n",
      "Epoch 37/300\n",
      "379/379 [==============================] - 0s - loss: 0.8104 - val_loss: 0.9128\n",
      "Epoch 38/300\n",
      "379/379 [==============================] - 0s - loss: 0.7902 - val_loss: 0.7942\n",
      "Epoch 39/300\n",
      "379/379 [==============================] - 0s - loss: 0.6765 - val_loss: 0.7246\n",
      "Epoch 40/300\n",
      "379/379 [==============================] - 0s - loss: 0.6289 - val_loss: 0.6989\n",
      "Epoch 41/300\n",
      "379/379 [==============================] - 0s - loss: 0.6170 - val_loss: 0.6558\n",
      "Epoch 42/300\n",
      "379/379 [==============================] - 0s - loss: 0.5413 - val_loss: 0.5875\n",
      "Epoch 43/300\n",
      "379/379 [==============================] - 0s - loss: 0.5144 - val_loss: 0.5491\n",
      "Epoch 44/300\n",
      "379/379 [==============================] - 0s - loss: 0.4777 - val_loss: 0.8305\n",
      "Epoch 45/300\n",
      "379/379 [==============================] - 0s - loss: 0.4614 - val_loss: 0.5180\n",
      "Epoch 46/300\n",
      "379/379 [==============================] - 0s - loss: 0.4828 - val_loss: 0.4711\n",
      "Epoch 47/300\n",
      "379/379 [==============================] - 0s - loss: 0.4200 - val_loss: 0.5163\n",
      "Epoch 48/300\n",
      "379/379 [==============================] - 0s - loss: 0.4016 - val_loss: 0.4340\n",
      "Epoch 49/300\n",
      "379/379 [==============================] - 0s - loss: 0.3962 - val_loss: 0.4062\n",
      "Epoch 50/300\n",
      "379/379 [==============================] - 0s - loss: 0.3692 - val_loss: 0.4885\n",
      "Epoch 51/300\n",
      "379/379 [==============================] - 0s - loss: 0.3684 - val_loss: 0.4960\n",
      "Epoch 52/300\n",
      "379/379 [==============================] - 0s - loss: 0.3474 - val_loss: 0.3675\n",
      "Epoch 53/300\n",
      "379/379 [==============================] - 0s - loss: 0.3699 - val_loss: 0.4146\n",
      "Epoch 54/300\n",
      "379/379 [==============================] - 0s - loss: 0.3332 - val_loss: 0.3686\n",
      "Epoch 55/300\n",
      "379/379 [==============================] - 0s - loss: 0.3348 - val_loss: 0.4511\n",
      "Epoch 56/300\n",
      "379/379 [==============================] - 0s - loss: 0.3074 - val_loss: 0.4036\n",
      "Epoch 57/300\n",
      "379/379 [==============================] - 0s - loss: 0.3063 - val_loss: 0.3389\n",
      "Epoch 58/300\n",
      "379/379 [==============================] - 0s - loss: 0.3024 - val_loss: 0.3750\n",
      "Epoch 59/300\n",
      "379/379 [==============================] - 0s - loss: 0.3003 - val_loss: 0.5136\n",
      "Epoch 60/300\n",
      "379/379 [==============================] - 0s - loss: 0.2950 - val_loss: 0.3303\n",
      "Epoch 61/300\n",
      "379/379 [==============================] - 0s - loss: 0.2906 - val_loss: 0.3237\n",
      "Epoch 62/300\n",
      "379/379 [==============================] - 0s - loss: 0.2756 - val_loss: 0.3752\n",
      "Epoch 63/300\n",
      "379/379 [==============================] - 0s - loss: 0.2753 - val_loss: 0.2939\n",
      "Epoch 64/300\n",
      "379/379 [==============================] - 0s - loss: 0.2709 - val_loss: 0.3440\n",
      "Epoch 65/300\n",
      "379/379 [==============================] - 0s - loss: 0.2641 - val_loss: 0.3256\n",
      "Epoch 66/300\n",
      "379/379 [==============================] - 0s - loss: 0.2692 - val_loss: 0.3280\n",
      "Epoch 67/300\n",
      "379/379 [==============================] - 0s - loss: 0.2580 - val_loss: 0.3204\n",
      "Epoch 68/300\n",
      "379/379 [==============================] - 0s - loss: 0.2641 - val_loss: 0.2717\n",
      "Epoch 69/300\n",
      "379/379 [==============================] - 0s - loss: 0.2653 - val_loss: 0.3010\n",
      "Epoch 70/300\n",
      "379/379 [==============================] - 0s - loss: 0.2577 - val_loss: 0.3005\n",
      "Epoch 71/300\n",
      "379/379 [==============================] - 0s - loss: 0.2547 - val_loss: 0.3531\n",
      "Epoch 72/300\n",
      "379/379 [==============================] - 0s - loss: 0.2467 - val_loss: 0.2704\n",
      "Epoch 73/300\n",
      "379/379 [==============================] - 0s - loss: 0.2425 - val_loss: 0.2538\n",
      "Epoch 74/300\n",
      "379/379 [==============================] - 0s - loss: 0.2518 - val_loss: 0.3816\n",
      "Epoch 75/300\n",
      "379/379 [==============================] - 0s - loss: 0.2612 - val_loss: 0.2848\n",
      "Epoch 76/300\n",
      "379/379 [==============================] - 0s - loss: 0.2402 - val_loss: 0.2957\n",
      "Epoch 77/300\n",
      "379/379 [==============================] - 0s - loss: 0.2361 - val_loss: 0.2546\n",
      "Epoch 78/300\n",
      "379/379 [==============================] - 0s - loss: 0.2273 - val_loss: 0.6674\n",
      "Epoch 79/300\n",
      "379/379 [==============================] - 0s - loss: 0.2479 - val_loss: 0.3050\n",
      "Epoch 80/300\n",
      "379/379 [==============================] - 0s - loss: 0.2415 - val_loss: 0.2586\n",
      "Epoch 81/300\n",
      "379/379 [==============================] - 0s - loss: 0.2265 - val_loss: 0.3884\n",
      "Epoch 82/300\n",
      "379/379 [==============================] - 0s - loss: 0.2575 - val_loss: 0.2514\n",
      "Epoch 83/300\n",
      "379/379 [==============================] - 0s - loss: 0.2197 - val_loss: 0.3349\n",
      "Epoch 84/300\n",
      "379/379 [==============================] - 0s - loss: 0.2225 - val_loss: 0.2368\n",
      "Epoch 85/300\n",
      "379/379 [==============================] - 0s - loss: 0.2356 - val_loss: 0.2521\n",
      "Epoch 86/300\n",
      "379/379 [==============================] - 0s - loss: 0.2148 - val_loss: 0.2742\n",
      "Epoch 87/300\n",
      "379/379 [==============================] - 0s - loss: 0.2272 - val_loss: 0.2749\n",
      "Epoch 88/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s - loss: 0.2168 - val_loss: 0.2328\n",
      "Epoch 89/300\n",
      "379/379 [==============================] - 0s - loss: 0.2222 - val_loss: 0.2708\n",
      "Epoch 90/300\n",
      "379/379 [==============================] - 0s - loss: 0.2124 - val_loss: 0.2724\n",
      "Epoch 91/300\n",
      "379/379 [==============================] - 0s - loss: 0.2032 - val_loss: 0.3133\n",
      "Epoch 92/300\n",
      "379/379 [==============================] - 0s - loss: 0.2161 - val_loss: 0.2718\n",
      "Epoch 93/300\n",
      "379/379 [==============================] - 0s - loss: 0.2054 - val_loss: 0.3316\n",
      "Epoch 94/300\n",
      "379/379 [==============================] - 0s - loss: 0.2084 - val_loss: 0.3424\n",
      "Epoch 95/300\n",
      "379/379 [==============================] - 0s - loss: 0.2097 - val_loss: 0.2196\n",
      "Epoch 96/300\n",
      "379/379 [==============================] - 0s - loss: 0.2048 - val_loss: 0.2332\n",
      "Epoch 97/300\n",
      "379/379 [==============================] - 0s - loss: 0.2029 - val_loss: 0.2273\n",
      "Epoch 98/300\n",
      "379/379 [==============================] - 0s - loss: 0.2020 - val_loss: 0.2502\n",
      "Epoch 99/300\n",
      "379/379 [==============================] - 0s - loss: 0.1973 - val_loss: 0.2360\n",
      "Epoch 100/300\n",
      "379/379 [==============================] - 0s - loss: 0.2032 - val_loss: 0.2704\n",
      "Epoch 101/300\n",
      "379/379 [==============================] - 0s - loss: 0.1941 - val_loss: 0.3056\n",
      "Epoch 102/300\n",
      "379/379 [==============================] - 0s - loss: 0.1986 - val_loss: 0.2709\n",
      "Epoch 103/300\n",
      "379/379 [==============================] - 0s - loss: 0.1914 - val_loss: 0.2601\n",
      "Epoch 104/300\n",
      "379/379 [==============================] - 0s - loss: 0.1909 - val_loss: 0.2020\n",
      "Epoch 105/300\n",
      "379/379 [==============================] - 0s - loss: 0.1938 - val_loss: 0.2172\n",
      "Epoch 106/300\n",
      "379/379 [==============================] - 0s - loss: 0.1874 - val_loss: 0.2780\n",
      "Epoch 107/300\n",
      "379/379 [==============================] - 0s - loss: 0.1858 - val_loss: 0.2158\n",
      "Epoch 108/300\n",
      "379/379 [==============================] - 0s - loss: 0.1862 - val_loss: 0.2366\n",
      "Epoch 109/300\n",
      "379/379 [==============================] - 0s - loss: 0.1852 - val_loss: 0.2459\n",
      "Epoch 110/300\n",
      "379/379 [==============================] - 0s - loss: 0.1789 - val_loss: 0.3159\n",
      "Epoch 111/300\n",
      "379/379 [==============================] - 0s - loss: 0.1924 - val_loss: 0.2865\n",
      "Epoch 112/300\n",
      "379/379 [==============================] - 0s - loss: 0.1758 - val_loss: 0.2721\n",
      "Epoch 113/300\n",
      "379/379 [==============================] - 0s - loss: 0.1777 - val_loss: 0.2247\n",
      "Epoch 114/300\n",
      "379/379 [==============================] - 0s - loss: 0.1845 - val_loss: 0.2661\n",
      "Epoch 115/300\n",
      "379/379 [==============================] - 0s - loss: 0.1752 - val_loss: 0.2647\n",
      "Epoch 116/300\n",
      "379/379 [==============================] - 0s - loss: 0.1730 - val_loss: 0.2161\n",
      "Epoch 117/300\n",
      "379/379 [==============================] - 0s - loss: 0.1842 - val_loss: 0.1984\n",
      "Epoch 118/300\n",
      "379/379 [==============================] - 0s - loss: 0.1788 - val_loss: 0.2222\n",
      "Epoch 119/300\n",
      "379/379 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2368\n",
      "Epoch 120/300\n",
      "379/379 [==============================] - 0s - loss: 0.1797 - val_loss: 0.2426\n",
      "Epoch 121/300\n",
      "379/379 [==============================] - 0s - loss: 0.1640 - val_loss: 0.2015\n",
      "Epoch 122/300\n",
      "379/379 [==============================] - 0s - loss: 0.1827 - val_loss: 0.1926\n",
      "Epoch 123/300\n",
      "379/379 [==============================] - 0s - loss: 0.1859 - val_loss: 0.2355\n",
      "Epoch 124/300\n",
      "379/379 [==============================] - 0s - loss: 0.1723 - val_loss: 0.2128\n",
      "Epoch 125/300\n",
      "379/379 [==============================] - 0s - loss: 0.1691 - val_loss: 0.2085\n",
      "Epoch 126/300\n",
      "379/379 [==============================] - 0s - loss: 0.1721 - val_loss: 0.2209\n",
      "Epoch 127/300\n",
      "379/379 [==============================] - 0s - loss: 0.1633 - val_loss: 0.2524\n",
      "Epoch 128/300\n",
      "379/379 [==============================] - 0s - loss: 0.1631 - val_loss: 0.1872\n",
      "Epoch 129/300\n",
      "379/379 [==============================] - 0s - loss: 0.1723 - val_loss: 0.2176\n",
      "Epoch 130/300\n",
      "379/379 [==============================] - 0s - loss: 0.1735 - val_loss: 0.1708\n",
      "Epoch 131/300\n",
      "379/379 [==============================] - 0s - loss: 0.1623 - val_loss: 0.2452\n",
      "Epoch 132/300\n",
      "379/379 [==============================] - 0s - loss: 0.1571 - val_loss: 0.1786\n",
      "Epoch 133/300\n",
      "379/379 [==============================] - 0s - loss: 0.1638 - val_loss: 0.1902\n",
      "Epoch 134/300\n",
      "379/379 [==============================] - 0s - loss: 0.1694 - val_loss: 0.2377\n",
      "Epoch 135/300\n",
      "379/379 [==============================] - 0s - loss: 0.1635 - val_loss: 0.2826\n",
      "Epoch 136/300\n",
      "379/379 [==============================] - 0s - loss: 0.1610 - val_loss: 0.1747\n",
      "Epoch 137/300\n",
      "379/379 [==============================] - 0s - loss: 0.1609 - val_loss: 0.2161\n",
      "Epoch 138/300\n",
      "379/379 [==============================] - 0s - loss: 0.1505 - val_loss: 0.2993\n",
      "Epoch 139/300\n",
      "379/379 [==============================] - 0s - loss: 0.1547 - val_loss: 0.2391\n",
      "Epoch 140/300\n",
      "379/379 [==============================] - 0s - loss: 0.1495 - val_loss: 0.2309\n",
      "Epoch 141/300\n",
      "379/379 [==============================] - 0s - loss: 0.1556 - val_loss: 0.2159\n",
      "Epoch 142/300\n",
      "379/379 [==============================] - 0s - loss: 0.1656 - val_loss: 0.1800\n",
      "Epoch 143/300\n",
      "379/379 [==============================] - 0s - loss: 0.1595 - val_loss: 0.2323\n",
      "Epoch 144/300\n",
      "379/379 [==============================] - 0s - loss: 0.1529 - val_loss: 0.2087\n",
      "Epoch 145/300\n",
      "379/379 [==============================] - 0s - loss: 0.1563 - val_loss: 0.2091\n",
      "Epoch 146/300\n",
      "379/379 [==============================] - 0s - loss: 0.1478 - val_loss: 0.1756\n",
      "Epoch 147/300\n",
      "379/379 [==============================] - 0s - loss: 0.1507 - val_loss: 0.2139\n",
      "Epoch 148/300\n",
      "379/379 [==============================] - 0s - loss: 0.1495 - val_loss: 0.1753\n",
      "Epoch 149/300\n",
      "379/379 [==============================] - 0s - loss: 0.1533 - val_loss: 0.2061\n",
      "Epoch 150/300\n",
      "379/379 [==============================] - 0s - loss: 0.1498 - val_loss: 0.1927\n",
      "Epoch 151/300\n",
      "379/379 [==============================] - 0s - loss: 0.1572 - val_loss: 0.1975\n",
      "Epoch 152/300\n",
      "379/379 [==============================] - 0s - loss: 0.1456 - val_loss: 0.2603\n",
      "Epoch 153/300\n",
      "379/379 [==============================] - 0s - loss: 0.1436 - val_loss: 0.2075\n",
      "Epoch 154/300\n",
      "379/379 [==============================] - 0s - loss: 0.1437 - val_loss: 0.1731\n",
      "Epoch 155/300\n",
      "379/379 [==============================] - 0s - loss: 0.1478 - val_loss: 0.1579\n",
      "Epoch 156/300\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.074 - 0s - loss: 0.1486 - val_loss: 0.1803\n",
      "Epoch 157/300\n",
      "379/379 [==============================] - 0s - loss: 0.1439 - val_loss: 0.2527\n",
      "Epoch 158/300\n",
      "379/379 [==============================] - 0s - loss: 0.1438 - val_loss: 0.1867\n",
      "Epoch 159/300\n",
      "379/379 [==============================] - 0s - loss: 0.1441 - val_loss: 0.1982\n",
      "Epoch 160/300\n",
      "379/379 [==============================] - 0s - loss: 0.1396 - val_loss: 0.2510\n",
      "Epoch 161/300\n",
      "379/379 [==============================] - 0s - loss: 0.1369 - val_loss: 0.1583\n",
      "Epoch 162/300\n",
      "379/379 [==============================] - 0s - loss: 0.1376 - val_loss: 0.2157\n",
      "Epoch 163/300\n",
      "379/379 [==============================] - 0s - loss: 0.1383 - val_loss: 0.2370\n",
      "Epoch 164/300\n",
      "379/379 [==============================] - 0s - loss: 0.1376 - val_loss: 0.2298\n",
      "Epoch 165/300\n",
      "379/379 [==============================] - 0s - loss: 0.1323 - val_loss: 0.2235\n",
      "Epoch 166/300\n",
      "379/379 [==============================] - 0s - loss: 0.1317 - val_loss: 0.2545\n",
      "Epoch 167/300\n",
      "379/379 [==============================] - 0s - loss: 0.1347 - val_loss: 0.1641\n",
      "Epoch 168/300\n",
      "379/379 [==============================] - 0s - loss: 0.1355 - val_loss: 0.2092\n",
      "Epoch 169/300\n",
      "379/379 [==============================] - 0s - loss: 0.1323 - val_loss: 0.2903\n",
      "Epoch 170/300\n",
      "379/379 [==============================] - 0s - loss: 0.1384 - val_loss: 0.2211\n",
      "Epoch 171/300\n",
      "379/379 [==============================] - 0s - loss: 0.1455 - val_loss: 0.1553\n",
      "Epoch 172/300\n",
      "379/379 [==============================] - 0s - loss: 0.1317 - val_loss: 0.2387\n",
      "Epoch 173/300\n",
      "379/379 [==============================] - 0s - loss: 0.1406 - val_loss: 0.2016\n",
      "Epoch 174/300\n",
      "379/379 [==============================] - 0s - loss: 0.1314 - val_loss: 0.2547\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s - loss: 0.1336 - val_loss: 0.2546\n",
      "Epoch 176/300\n",
      "379/379 [==============================] - 0s - loss: 0.1338 - val_loss: 0.1999\n",
      "Epoch 177/300\n",
      "379/379 [==============================] - 0s - loss: 0.1364 - val_loss: 0.1727\n",
      "Epoch 178/300\n",
      "379/379 [==============================] - 0s - loss: 0.1279 - val_loss: 0.2347\n",
      "Epoch 179/300\n",
      "379/379 [==============================] - 0s - loss: 0.1286 - val_loss: 0.2649\n",
      "Epoch 180/300\n",
      "379/379 [==============================] - 0s - loss: 0.1345 - val_loss: 0.2146\n",
      "Epoch 181/300\n",
      "379/379 [==============================] - 0s - loss: 0.1264 - val_loss: 0.1896\n",
      "Epoch 182/300\n",
      "379/379 [==============================] - 0s - loss: 0.1392 - val_loss: 0.2617\n",
      "Epoch 183/300\n",
      "379/379 [==============================] - 0s - loss: 0.1314 - val_loss: 0.1877\n",
      "Epoch 184/300\n",
      "379/379 [==============================] - 0s - loss: 0.1267 - val_loss: 0.2080\n",
      "Epoch 185/300\n",
      "379/379 [==============================] - 0s - loss: 0.1233 - val_loss: 0.1647\n",
      "Epoch 186/300\n",
      "379/379 [==============================] - 0s - loss: 0.1234 - val_loss: 0.1772\n",
      "Epoch 187/300\n",
      "379/379 [==============================] - 0s - loss: 0.1300 - val_loss: 0.1680\n",
      "Epoch 188/300\n",
      "379/379 [==============================] - 0s - loss: 0.1219 - val_loss: 0.2045\n",
      "Epoch 189/300\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.057 - 0s - loss: 0.1245 - val_loss: 0.2378\n",
      "Epoch 190/300\n",
      "379/379 [==============================] - 0s - loss: 0.1260 - val_loss: 0.2260\n",
      "Epoch 191/300\n",
      "379/379 [==============================] - 0s - loss: 0.1259 - val_loss: 0.1664\n",
      "Epoch 192/300\n",
      "379/379 [==============================] - 0s - loss: 0.1185 - val_loss: 0.1941\n",
      "Epoch 193/300\n",
      "379/379 [==============================] - 0s - loss: 0.1207 - val_loss: 0.2399\n",
      "Epoch 194/300\n",
      "379/379 [==============================] - 0s - loss: 0.1172 - val_loss: 0.2064\n",
      "Epoch 195/300\n",
      "379/379 [==============================] - 0s - loss: 0.1197 - val_loss: 0.2122\n",
      "Epoch 196/300\n",
      "379/379 [==============================] - 0s - loss: 0.1257 - val_loss: 0.1925\n",
      "Epoch 197/300\n",
      "379/379 [==============================] - 0s - loss: 0.1250 - val_loss: 0.1416\n",
      "Epoch 198/300\n",
      "379/379 [==============================] - 0s - loss: 0.1206 - val_loss: 0.2800\n",
      "Epoch 199/300\n",
      "379/379 [==============================] - 0s - loss: 0.1173 - val_loss: 0.1341\n",
      "Epoch 200/300\n",
      "379/379 [==============================] - 0s - loss: 0.1262 - val_loss: 0.1723\n",
      "Epoch 201/300\n",
      "379/379 [==============================] - 0s - loss: 0.1170 - val_loss: 0.1738\n",
      "Epoch 202/300\n",
      "379/379 [==============================] - 0s - loss: 0.1184 - val_loss: 0.1837\n",
      "Epoch 203/300\n",
      "379/379 [==============================] - 0s - loss: 0.1198 - val_loss: 0.1900\n",
      "Epoch 204/300\n",
      "379/379 [==============================] - 0s - loss: 0.1153 - val_loss: 0.2647\n",
      "Epoch 205/300\n",
      "379/379 [==============================] - 0s - loss: 0.1149 - val_loss: 0.2135\n",
      "Epoch 206/300\n",
      "379/379 [==============================] - 0s - loss: 0.1169 - val_loss: 0.2072\n",
      "Epoch 207/300\n",
      "379/379 [==============================] - 0s - loss: 0.1128 - val_loss: 0.2150\n",
      "Epoch 208/300\n",
      "379/379 [==============================] - 0s - loss: 0.1144 - val_loss: 0.1841\n",
      "Epoch 209/300\n",
      "379/379 [==============================] - 0s - loss: 0.1111 - val_loss: 0.1373\n",
      "Epoch 210/300\n",
      "379/379 [==============================] - 0s - loss: 0.1131 - val_loss: 0.1504\n",
      "Epoch 211/300\n",
      "379/379 [==============================] - 0s - loss: 0.1107 - val_loss: 0.1837\n",
      "Epoch 212/300\n",
      "379/379 [==============================] - 0s - loss: 0.1176 - val_loss: 0.2049\n",
      "Epoch 213/300\n",
      "379/379 [==============================] - 0s - loss: 0.1129 - val_loss: 0.1483\n",
      "Epoch 214/300\n",
      "379/379 [==============================] - 0s - loss: 0.1108 - val_loss: 0.1576\n",
      "Epoch 215/300\n",
      "379/379 [==============================] - 0s - loss: 0.1202 - val_loss: 0.1755\n",
      "Epoch 216/300\n",
      "379/379 [==============================] - 0s - loss: 0.1082 - val_loss: 0.1978\n",
      "Epoch 217/300\n",
      "379/379 [==============================] - 0s - loss: 0.1078 - val_loss: 0.1595\n",
      "Epoch 218/300\n",
      "379/379 [==============================] - 0s - loss: 0.1097 - val_loss: 0.1530\n",
      "Epoch 219/300\n",
      "379/379 [==============================] - 0s - loss: 0.1085 - val_loss: 0.1923\n",
      "Epoch 220/300\n",
      "379/379 [==============================] - 0s - loss: 0.1074 - val_loss: 0.1428\n",
      "Epoch 221/300\n",
      "379/379 [==============================] - 0s - loss: 0.1084 - val_loss: 0.1414\n",
      "Epoch 222/300\n",
      "379/379 [==============================] - 0s - loss: 0.1092 - val_loss: 0.1320\n",
      "Epoch 223/300\n",
      "379/379 [==============================] - 0s - loss: 0.1055 - val_loss: 0.2090\n",
      "Epoch 224/300\n",
      "379/379 [==============================] - 0s - loss: 0.1080 - val_loss: 0.1520\n",
      "Epoch 225/300\n",
      "379/379 [==============================] - 0s - loss: 0.1046 - val_loss: 0.1511\n",
      "Epoch 226/300\n",
      "379/379 [==============================] - 0s - loss: 0.1046 - val_loss: 0.1371\n",
      "Epoch 227/300\n",
      "379/379 [==============================] - 0s - loss: 0.1051 - val_loss: 0.1867\n",
      "Epoch 228/300\n",
      "379/379 [==============================] - 0s - loss: 0.1077 - val_loss: 0.1942\n",
      "Epoch 229/300\n",
      "379/379 [==============================] - 0s - loss: 0.1041 - val_loss: 0.2678\n",
      "Epoch 230/300\n",
      "379/379 [==============================] - 0s - loss: 0.1051 - val_loss: 0.2136\n",
      "Epoch 231/300\n",
      "379/379 [==============================] - 0s - loss: 0.1033 - val_loss: 0.2067\n",
      "Epoch 232/300\n",
      "379/379 [==============================] - 0s - loss: 0.1029 - val_loss: 0.2094\n",
      "Epoch 233/300\n",
      "379/379 [==============================] - 0s - loss: 0.1017 - val_loss: 0.1466\n",
      "Epoch 234/300\n",
      "379/379 [==============================] - 0s - loss: 0.1040 - val_loss: 0.1405\n",
      "Epoch 235/300\n",
      "379/379 [==============================] - 0s - loss: 0.1055 - val_loss: 0.1964\n",
      "Epoch 236/300\n",
      "379/379 [==============================] - 0s - loss: 0.1032 - val_loss: 0.2330\n",
      "Epoch 237/300\n",
      "379/379 [==============================] - 0s - loss: 0.1081 - val_loss: 0.3040\n",
      "Epoch 238/300\n",
      "379/379 [==============================] - 0s - loss: 0.1024 - val_loss: 0.1781\n",
      "Epoch 239/300\n",
      "379/379 [==============================] - 0s - loss: 0.0981 - val_loss: 0.1991\n",
      "Epoch 240/300\n",
      "379/379 [==============================] - 0s - loss: 0.1065 - val_loss: 0.2318\n",
      "Epoch 241/300\n",
      "379/379 [==============================] - 0s - loss: 0.1042 - val_loss: 0.1791\n",
      "Epoch 242/300\n",
      "379/379 [==============================] - 0s - loss: 0.0998 - val_loss: 0.1625\n",
      "Epoch 243/300\n",
      "379/379 [==============================] - 0s - loss: 0.0986 - val_loss: 0.2167\n",
      "Epoch 244/300\n",
      "379/379 [==============================] - 0s - loss: 0.1023 - val_loss: 0.1662\n",
      "Epoch 245/300\n",
      "379/379 [==============================] - 0s - loss: 0.1016 - val_loss: 0.1868\n",
      "Epoch 246/300\n",
      "379/379 [==============================] - 0s - loss: 0.0971 - val_loss: 0.1996\n",
      "Epoch 247/300\n",
      "379/379 [==============================] - 0s - loss: 0.0964 - val_loss: 0.1843\n",
      "Epoch 248/300\n",
      "379/379 [==============================] - 0s - loss: 0.0999 - val_loss: 0.1399\n",
      "Epoch 249/300\n",
      "379/379 [==============================] - 0s - loss: 0.0975 - val_loss: 0.1903\n",
      "Epoch 250/300\n",
      "379/379 [==============================] - 0s - loss: 0.0976 - val_loss: 0.1484\n",
      "Epoch 251/300\n",
      "379/379 [==============================] - 0s - loss: 0.0993 - val_loss: 0.1482\n",
      "Epoch 252/300\n",
      "379/379 [==============================] - 0s - loss: 0.0974 - val_loss: 0.1813\n",
      "Epoch 253/300\n",
      "379/379 [==============================] - 0s - loss: 0.0968 - val_loss: 0.1556\n",
      "Epoch 254/300\n",
      "379/379 [==============================] - 0s - loss: 0.0939 - val_loss: 0.2437\n",
      "Epoch 255/300\n",
      "379/379 [==============================] - 0s - loss: 0.1006 - val_loss: 0.1369\n",
      "Epoch 256/300\n",
      "379/379 [==============================] - 0s - loss: 0.0947 - val_loss: 0.1667\n",
      "Epoch 257/300\n",
      "379/379 [==============================] - 0s - loss: 0.0922 - val_loss: 0.1830\n",
      "Epoch 258/300\n",
      "379/379 [==============================] - 0s - loss: 0.0955 - val_loss: 0.2233\n",
      "Epoch 259/300\n",
      "379/379 [==============================] - 0s - loss: 0.0915 - val_loss: 0.2058\n",
      "Epoch 260/300\n",
      "379/379 [==============================] - 0s - loss: 0.0914 - val_loss: 0.1647\n",
      "Epoch 261/300\n",
      "379/379 [==============================] - 0s - loss: 0.0926 - val_loss: 0.1601\n",
      "Epoch 262/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s - loss: 0.0966 - val_loss: 0.1893\n",
      "Epoch 263/300\n",
      "379/379 [==============================] - 0s - loss: 0.0971 - val_loss: 0.1632\n",
      "Epoch 264/300\n",
      "379/379 [==============================] - 0s - loss: 0.0926 - val_loss: 0.2044\n",
      "Epoch 265/300\n",
      "379/379 [==============================] - 0s - loss: 0.0919 - val_loss: 0.1940\n",
      "Epoch 266/300\n",
      "379/379 [==============================] - 0s - loss: 0.0939 - val_loss: 0.1713\n",
      "Epoch 267/300\n",
      "379/379 [==============================] - 0s - loss: 0.0914 - val_loss: 0.1233\n",
      "Epoch 268/300\n",
      "379/379 [==============================] - 0s - loss: 0.0913 - val_loss: 0.1655\n",
      "Epoch 269/300\n",
      "379/379 [==============================] - 0s - loss: 0.0920 - val_loss: 0.1516\n",
      "Epoch 270/300\n",
      "379/379 [==============================] - 0s - loss: 0.0939 - val_loss: 0.2693\n",
      "Epoch 271/300\n",
      "379/379 [==============================] - 0s - loss: 0.0969 - val_loss: 0.1796\n",
      "Epoch 272/300\n",
      "379/379 [==============================] - 0s - loss: 0.0935 - val_loss: 0.2210\n",
      "Epoch 273/300\n",
      "379/379 [==============================] - 0s - loss: 0.1002 - val_loss: 0.1880\n",
      "Epoch 274/300\n",
      "379/379 [==============================] - 0s - loss: 0.0885 - val_loss: 0.1736\n",
      "Epoch 275/300\n",
      "379/379 [==============================] - 0s - loss: 0.0883 - val_loss: 0.1475\n",
      "Epoch 276/300\n",
      "379/379 [==============================] - 0s - loss: 0.0891 - val_loss: 0.1603\n",
      "Epoch 277/300\n",
      "379/379 [==============================] - 0s - loss: 0.0896 - val_loss: 0.2024\n",
      "Epoch 278/300\n",
      "379/379 [==============================] - 0s - loss: 0.0897 - val_loss: 0.2018\n",
      "Epoch 279/300\n",
      "379/379 [==============================] - 0s - loss: 0.0950 - val_loss: 0.1769\n",
      "Epoch 280/300\n",
      "379/379 [==============================] - 0s - loss: 0.0879 - val_loss: 0.1492\n",
      "Epoch 281/300\n",
      "379/379 [==============================] - 0s - loss: 0.0878 - val_loss: 0.2161\n",
      "Epoch 282/300\n",
      "379/379 [==============================] - 0s - loss: 0.0900 - val_loss: 0.2200\n",
      "Epoch 283/300\n",
      "379/379 [==============================] - 0s - loss: 0.0863 - val_loss: 0.1899\n",
      "Epoch 284/300\n",
      "379/379 [==============================] - 0s - loss: 0.0897 - val_loss: 0.1315\n",
      "Epoch 285/300\n",
      "379/379 [==============================] - 0s - loss: 0.0853 - val_loss: 0.1449\n",
      "Epoch 286/300\n",
      "379/379 [==============================] - 0s - loss: 0.0873 - val_loss: 0.1518\n",
      "Epoch 287/300\n",
      "379/379 [==============================] - 0s - loss: 0.0876 - val_loss: 0.1409\n",
      "Epoch 288/300\n",
      "379/379 [==============================] - 0s - loss: 0.0873 - val_loss: 0.1721\n",
      "Epoch 289/300\n",
      "379/379 [==============================] - 0s - loss: 0.0949 - val_loss: 0.1660\n",
      "Epoch 290/300\n",
      "379/379 [==============================] - 0s - loss: 0.0825 - val_loss: 0.1804\n",
      "Epoch 291/300\n",
      "379/379 [==============================] - 0s - loss: 0.0845 - val_loss: 0.1715\n",
      "Epoch 292/300\n",
      "379/379 [==============================] - 0s - loss: 0.0846 - val_loss: 0.1612\n",
      "Epoch 293/300\n",
      "379/379 [==============================] - 0s - loss: 0.0826 - val_loss: 0.1728\n",
      "Epoch 294/300\n",
      "379/379 [==============================] - 0s - loss: 0.0825 - val_loss: 0.1774\n",
      "Epoch 295/300\n",
      "379/379 [==============================] - 0s - loss: 0.0821 - val_loss: 0.1287\n",
      "Epoch 296/300\n",
      "379/379 [==============================] - 0s - loss: 0.0803 - val_loss: 0.1890\n",
      "Epoch 297/300\n",
      "379/379 [==============================] - 0s - loss: 0.0835 - val_loss: 0.1964\n",
      "Epoch 298/300\n",
      "379/379 [==============================] - 0s - loss: 0.0831 - val_loss: 0.1798\n",
      "Epoch 299/300\n",
      "379/379 [==============================] - 0s - loss: 0.0831 - val_loss: 0.1569\n",
      "Epoch 300/300\n",
      "379/379 [==============================] - 0s - loss: 0.0818 - val_loss: 0.1553\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=X_train_scaled.shape[1], init='uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(1, init='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,loss='mean_squared_error')\n",
    "\n",
    "hist = model.fit(X_train_scaled.as_matrix(), y_train.as_matrix(), nb_epoch=300,\n",
    "verbose=1, validation_data=(X_test_scaled.as_matrix(), y_test.as_matrix()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) repetir (c) pero con relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/.local/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, kernel_initializer=\"uniform\", input_dim=14)`\n",
      "  \n",
      "/home/felipe/.local/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/300\n",
      "379/379 [==============================] - 0s - loss: 271.8296 - val_loss: 32.9255\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 0s - loss: 14.3060 - val_loss: 11.2338\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 0s - loss: 5.8620 - val_loss: 5.9283\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 0s - loss: 3.2715 - val_loss: 4.3458\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 0s - loss: 2.4414 - val_loss: 3.0733\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 0s - loss: 2.3999 - val_loss: 2.1777\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 0s - loss: 1.4123 - val_loss: 1.7104\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 0s - loss: 1.1747 - val_loss: 1.4588\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 0s - loss: 0.9345 - val_loss: 1.8251\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 0s - loss: 0.9269 - val_loss: 1.4035\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 0s - loss: 0.7381 - val_loss: 1.9784\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 0s - loss: 0.7264 - val_loss: 1.5502\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 0s - loss: 0.6511 - val_loss: 1.2638\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 0s - loss: 0.7347 - val_loss: 1.1391\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 0s - loss: 0.4921 - val_loss: 0.9294\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 0s - loss: 0.5713 - val_loss: 0.6374\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 0s - loss: 0.3973 - val_loss: 0.7836\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 0s - loss: 0.3385 - val_loss: 1.1122\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 0s - loss: 0.7512 - val_loss: 0.8881\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 0s - loss: 0.4399 - val_loss: 0.8097\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 0s - loss: 0.5791 - val_loss: 0.5685\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 0s - loss: 0.2555 - val_loss: 0.4275\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 0s - loss: 0.2576 - val_loss: 0.7030\n",
      "Epoch 24/300\n",
      "379/379 [==============================] - 0s - loss: 0.4118 - val_loss: 0.9973\n",
      "Epoch 25/300\n",
      "379/379 [==============================] - 0s - loss: 0.5337 - val_loss: 0.4257\n",
      "Epoch 26/300\n",
      "379/379 [==============================] - 0s - loss: 0.2019 - val_loss: 0.7233\n",
      "Epoch 27/300\n",
      "379/379 [==============================] - 0s - loss: 0.3500 - val_loss: 1.0752\n",
      "Epoch 28/300\n",
      "379/379 [==============================] - 0s - loss: 0.2163 - val_loss: 0.3567\n",
      "Epoch 29/300\n",
      "379/379 [==============================] - 0s - loss: 0.3522 - val_loss: 0.3529\n",
      "Epoch 30/300\n",
      "379/379 [==============================] - 0s - loss: 0.1891 - val_loss: 0.5749\n",
      "Epoch 31/300\n",
      "379/379 [==============================] - 0s - loss: 0.2658 - val_loss: 0.4993\n",
      "Epoch 32/300\n",
      "379/379 [==============================] - 0s - loss: 0.1531 - val_loss: 0.6168\n",
      "Epoch 33/300\n",
      "379/379 [==============================] - 0s - loss: 0.2060 - val_loss: 0.4983\n",
      "Epoch 34/300\n",
      "379/379 [==============================] - 0s - loss: 0.1674 - val_loss: 0.9655\n",
      "Epoch 35/300\n",
      "379/379 [==============================] - 0s - loss: 0.2337 - val_loss: 0.2708\n",
      "Epoch 36/300\n",
      "379/379 [==============================] - 0s - loss: 0.1702 - val_loss: 0.6857\n",
      "Epoch 37/300\n",
      "379/379 [==============================] - 0s - loss: 0.1968 - val_loss: 0.2326\n",
      "Epoch 38/300\n",
      "379/379 [==============================] - 0s - loss: 0.3617 - val_loss: 0.3368\n",
      "Epoch 39/300\n",
      "379/379 [==============================] - 0s - loss: 0.1517 - val_loss: 0.3856\n",
      "Epoch 40/300\n",
      "379/379 [==============================] - 0s - loss: 0.1158 - val_loss: 0.3200\n",
      "Epoch 41/300\n",
      "379/379 [==============================] - 0s - loss: 0.1735 - val_loss: 1.2780\n",
      "Epoch 42/300\n",
      "379/379 [==============================] - 0s - loss: 0.9403 - val_loss: 1.6180\n",
      "Epoch 43/300\n",
      "379/379 [==============================] - 0s - loss: 0.4079 - val_loss: 0.9743\n",
      "Epoch 44/300\n",
      "379/379 [==============================] - 0s - loss: 0.1707 - val_loss: 0.1946\n",
      "Epoch 45/300\n",
      "379/379 [==============================] - 0s - loss: 0.1940 - val_loss: 0.3035\n",
      "Epoch 46/300\n",
      "379/379 [==============================] - 0s - loss: 0.0876 - val_loss: 0.3067\n",
      "Epoch 47/300\n",
      "379/379 [==============================] - 0s - loss: 0.1974 - val_loss: 0.6533\n",
      "Epoch 48/300\n",
      "379/379 [==============================] - 0s - loss: 0.1162 - val_loss: 0.2604\n",
      "Epoch 49/300\n",
      "379/379 [==============================] - 0s - loss: 0.0929 - val_loss: 0.3201\n",
      "Epoch 50/300\n",
      "379/379 [==============================] - 0s - loss: 0.1511 - val_loss: 0.2066\n",
      "Epoch 51/300\n",
      "379/379 [==============================] - 0s - loss: 0.1157 - val_loss: 0.2610\n",
      "Epoch 52/300\n",
      "379/379 [==============================] - 0s - loss: 0.0895 - val_loss: 0.3799\n",
      "Epoch 53/300\n",
      "379/379 [==============================] - 0s - loss: 0.0708 - val_loss: 0.2929\n",
      "Epoch 54/300\n",
      "379/379 [==============================] - 0s - loss: 0.2263 - val_loss: 0.5234\n",
      "Epoch 55/300\n",
      "379/379 [==============================] - 0s - loss: 0.1338 - val_loss: 0.5095\n",
      "Epoch 56/300\n",
      "379/379 [==============================] - 0s - loss: 0.0995 - val_loss: 0.2839\n",
      "Epoch 57/300\n",
      "379/379 [==============================] - 0s - loss: 0.1597 - val_loss: 0.3969\n",
      "Epoch 58/300\n",
      "379/379 [==============================] - 0s - loss: 0.0836 - val_loss: 0.2932\n",
      "Epoch 59/300\n",
      "379/379 [==============================] - 0s - loss: 0.0894 - val_loss: 0.3223\n",
      "Epoch 60/300\n",
      "379/379 [==============================] - 0s - loss: 0.1152 - val_loss: 0.2092\n",
      "Epoch 61/300\n",
      "379/379 [==============================] - 0s - loss: 0.0810 - val_loss: 0.3287\n",
      "Epoch 62/300\n",
      "379/379 [==============================] - 0s - loss: 0.0795 - val_loss: 0.4504\n",
      "Epoch 63/300\n",
      "379/379 [==============================] - 0s - loss: 0.2627 - val_loss: 0.3460\n",
      "Epoch 64/300\n",
      "379/379 [==============================] - 0s - loss: 0.2396 - val_loss: 0.6284\n",
      "Epoch 65/300\n",
      "379/379 [==============================] - 0s - loss: 0.2013 - val_loss: 0.3211\n",
      "Epoch 66/300\n",
      "379/379 [==============================] - 0s - loss: 0.0652 - val_loss: 0.2094\n",
      "Epoch 67/300\n",
      "379/379 [==============================] - 0s - loss: 0.1318 - val_loss: 0.3295\n",
      "Epoch 68/300\n",
      "379/379 [==============================] - 0s - loss: 0.1884 - val_loss: 0.2782\n",
      "Epoch 69/300\n",
      "379/379 [==============================] - 0s - loss: 0.1346 - val_loss: 0.9776\n",
      "Epoch 70/300\n",
      "379/379 [==============================] - 0s - loss: 0.3807 - val_loss: 0.6914\n",
      "Epoch 71/300\n",
      "379/379 [==============================] - 0s - loss: 0.1694 - val_loss: 0.3146\n",
      "Epoch 72/300\n",
      "379/379 [==============================] - 0s - loss: 0.0469 - val_loss: 0.3074\n",
      "Epoch 73/300\n",
      "379/379 [==============================] - 0s - loss: 0.1743 - val_loss: 0.6718\n",
      "Epoch 74/300\n",
      "379/379 [==============================] - 0s - loss: 0.3214 - val_loss: 0.3261\n",
      "Epoch 75/300\n",
      "379/379 [==============================] - 0s - loss: 0.0640 - val_loss: 0.2744\n",
      "Epoch 76/300\n",
      "379/379 [==============================] - 0s - loss: 0.0480 - val_loss: 0.4033\n",
      "Epoch 77/300\n",
      "379/379 [==============================] - 0s - loss: 0.0491 - val_loss: 0.2899\n",
      "Epoch 78/300\n",
      "379/379 [==============================] - 0s - loss: 0.0400 - val_loss: 0.3205\n",
      "Epoch 79/300\n",
      "379/379 [==============================] - 0s - loss: 0.0635 - val_loss: 0.2540\n",
      "Epoch 80/300\n",
      "379/379 [==============================] - 0s - loss: 0.1664 - val_loss: 0.5232\n",
      "Epoch 81/300\n",
      "379/379 [==============================] - 0s - loss: 0.6402 - val_loss: 0.4527\n",
      "Epoch 82/300\n",
      "379/379 [==============================] - 0s - loss: 0.7069 - val_loss: 0.4672\n",
      "Epoch 83/300\n",
      "379/379 [==============================] - 0s - loss: 0.0817 - val_loss: 0.2738\n",
      "Epoch 84/300\n",
      "379/379 [==============================] - 0s - loss: 0.0724 - val_loss: 0.2201\n",
      "Epoch 85/300\n",
      "379/379 [==============================] - 0s - loss: 0.1373 - val_loss: 0.2710\n",
      "Epoch 86/300\n",
      "379/379 [==============================] - 0s - loss: 0.0423 - val_loss: 0.4319\n",
      "Epoch 87/300\n",
      "379/379 [==============================] - 0s - loss: 0.1140 - val_loss: 0.4789\n",
      "Epoch 88/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s - loss: 0.0687 - val_loss: 0.2523\n",
      "Epoch 89/300\n",
      "379/379 [==============================] - 0s - loss: 0.0350 - val_loss: 0.1791\n",
      "Epoch 90/300\n",
      "379/379 [==============================] - 0s - loss: 0.1902 - val_loss: 0.2484\n",
      "Epoch 91/300\n",
      "379/379 [==============================] - 0s - loss: 0.0717 - val_loss: 0.1631\n",
      "Epoch 92/300\n",
      "379/379 [==============================] - 0s - loss: 0.0853 - val_loss: 0.1769\n",
      "Epoch 93/300\n",
      "379/379 [==============================] - 0s - loss: 0.1395 - val_loss: 0.2243\n",
      "Epoch 94/300\n",
      "379/379 [==============================] - 0s - loss: 0.1102 - val_loss: 0.1510\n",
      "Epoch 95/300\n",
      "379/379 [==============================] - 0s - loss: 0.1047 - val_loss: 0.2185\n",
      "Epoch 96/300\n",
      "379/379 [==============================] - 0s - loss: 0.0389 - val_loss: 0.2571\n",
      "Epoch 97/300\n",
      "379/379 [==============================] - 0s - loss: 0.0371 - val_loss: 0.2776\n",
      "Epoch 98/300\n",
      "379/379 [==============================] - 0s - loss: 0.0354 - val_loss: 0.2849\n",
      "Epoch 99/300\n",
      "379/379 [==============================] - 0s - loss: 0.1717 - val_loss: 0.4712\n",
      "Epoch 100/300\n",
      "379/379 [==============================] - 0s - loss: 0.0958 - val_loss: 0.4706\n",
      "Epoch 101/300\n",
      "379/379 [==============================] - 0s - loss: 0.0503 - val_loss: 0.3630\n",
      "Epoch 102/300\n",
      "379/379 [==============================] - 0s - loss: 0.0427 - val_loss: 0.1794\n",
      "Epoch 103/300\n",
      "379/379 [==============================] - 0s - loss: 0.1303 - val_loss: 0.5197\n",
      "Epoch 104/300\n",
      "379/379 [==============================] - 0s - loss: 0.4714 - val_loss: 0.3530\n",
      "Epoch 105/300\n",
      "379/379 [==============================] - 0s - loss: 0.2834 - val_loss: 0.1421\n",
      "Epoch 106/300\n",
      "379/379 [==============================] - 0s - loss: 0.1332 - val_loss: 0.2016\n",
      "Epoch 107/300\n",
      "379/379 [==============================] - 0s - loss: 0.0357 - val_loss: 0.2615\n",
      "Epoch 108/300\n",
      "379/379 [==============================] - 0s - loss: 0.0258 - val_loss: 0.2881\n",
      "Epoch 109/300\n",
      "379/379 [==============================] - 0s - loss: 0.0284 - val_loss: 0.3244\n",
      "Epoch 110/300\n",
      "379/379 [==============================] - 0s - loss: 0.0259 - val_loss: 0.3025\n",
      "Epoch 111/300\n",
      "379/379 [==============================] - 0s - loss: 0.0355 - val_loss: 0.2533\n",
      "Epoch 112/300\n",
      "379/379 [==============================] - 0s - loss: 0.0239 - val_loss: 0.2477\n",
      "Epoch 113/300\n",
      "379/379 [==============================] - 0s - loss: 0.0348 - val_loss: 0.2453\n",
      "Epoch 114/300\n",
      "379/379 [==============================] - 0s - loss: 0.0224 - val_loss: 0.1984\n",
      "Epoch 115/300\n",
      "379/379 [==============================] - 0s - loss: 0.0409 - val_loss: 0.2238\n",
      "Epoch 116/300\n",
      "379/379 [==============================] - 0s - loss: 0.0404 - val_loss: 0.2682\n",
      "Epoch 117/300\n",
      "379/379 [==============================] - 0s - loss: 0.0264 - val_loss: 0.2746\n",
      "Epoch 118/300\n",
      "379/379 [==============================] - 0s - loss: 0.0456 - val_loss: 0.2800\n",
      "Epoch 119/300\n",
      "379/379 [==============================] - 0s - loss: 0.0398 - val_loss: 0.4343\n",
      "Epoch 120/300\n",
      "379/379 [==============================] - 0s - loss: 0.1060 - val_loss: 0.2814\n",
      "Epoch 121/300\n",
      "379/379 [==============================] - 0s - loss: 0.0248 - val_loss: 0.2451\n",
      "Epoch 122/300\n",
      "379/379 [==============================] - 0s - loss: 0.0626 - val_loss: 0.2611\n",
      "Epoch 123/300\n",
      "379/379 [==============================] - 0s - loss: 0.0214 - val_loss: 0.2127\n",
      "Epoch 124/300\n",
      "379/379 [==============================] - 0s - loss: 0.0206 - val_loss: 0.3252\n",
      "Epoch 125/300\n",
      "379/379 [==============================] - 0s - loss: 0.0601 - val_loss: 0.5121\n",
      "Epoch 126/300\n",
      "379/379 [==============================] - 0s - loss: 0.0345 - val_loss: 0.1960\n",
      "Epoch 127/300\n",
      "379/379 [==============================] - 0s - loss: 0.0578 - val_loss: 0.1265\n",
      "Epoch 128/300\n",
      "379/379 [==============================] - 0s - loss: 0.1676 - val_loss: 0.2212\n",
      "Epoch 129/300\n",
      "379/379 [==============================] - 0s - loss: 0.0290 - val_loss: 0.2647\n",
      "Epoch 130/300\n",
      "379/379 [==============================] - 0s - loss: 0.0216 - val_loss: 0.2175\n",
      "Epoch 131/300\n",
      "379/379 [==============================] - 0s - loss: 0.0185 - val_loss: 0.2188\n",
      "Epoch 132/300\n",
      "379/379 [==============================] - 0s - loss: 0.0395 - val_loss: 0.1884\n",
      "Epoch 133/300\n",
      "379/379 [==============================] - 0s - loss: 0.0247 - val_loss: 0.4090\n",
      "Epoch 134/300\n",
      "379/379 [==============================] - 0s - loss: 0.0804 - val_loss: 0.4101\n",
      "Epoch 135/300\n",
      "379/379 [==============================] - 0s - loss: 0.0375 - val_loss: 0.1836\n",
      "Epoch 136/300\n",
      "379/379 [==============================] - 0s - loss: 0.0323 - val_loss: 0.1742\n",
      "Epoch 137/300\n",
      "379/379 [==============================] - 0s - loss: 0.0915 - val_loss: 0.2050\n",
      "Epoch 138/300\n",
      "379/379 [==============================] - 0s - loss: 0.0276 - val_loss: 0.2188\n",
      "Epoch 139/300\n",
      "379/379 [==============================] - 0s - loss: 0.1049 - val_loss: 0.2028\n",
      "Epoch 140/300\n",
      "379/379 [==============================] - 0s - loss: 0.0325 - val_loss: 0.1508\n",
      "Epoch 141/300\n",
      "379/379 [==============================] - 0s - loss: 0.0332 - val_loss: 0.1869\n",
      "Epoch 142/300\n",
      "379/379 [==============================] - 0s - loss: 0.0216 - val_loss: 0.2032\n",
      "Epoch 143/300\n",
      "379/379 [==============================] - 0s - loss: 0.0177 - val_loss: 0.2581\n",
      "Epoch 144/300\n",
      "379/379 [==============================] - 0s - loss: 0.0357 - val_loss: 0.3735\n",
      "Epoch 145/300\n",
      "379/379 [==============================] - 0s - loss: 0.1608 - val_loss: 0.5903\n",
      "Epoch 146/300\n",
      "379/379 [==============================] - 0s - loss: 0.1453 - val_loss: 0.6031\n",
      "Epoch 147/300\n",
      "379/379 [==============================] - 0s - loss: 0.5563 - val_loss: 0.2909\n",
      "Epoch 148/300\n",
      "379/379 [==============================] - 0s - loss: 0.0305 - val_loss: 0.1824\n",
      "Epoch 149/300\n",
      "379/379 [==============================] - 0s - loss: 0.0479 - val_loss: 0.1917\n",
      "Epoch 150/300\n",
      "379/379 [==============================] - 0s - loss: 0.0173 - val_loss: 0.1781\n",
      "Epoch 151/300\n",
      "379/379 [==============================] - 0s - loss: 0.0260 - val_loss: 0.1512\n",
      "Epoch 152/300\n",
      "379/379 [==============================] - 0s - loss: 0.1567 - val_loss: 0.1609\n",
      "Epoch 153/300\n",
      "379/379 [==============================] - 0s - loss: 0.0830 - val_loss: 0.2663\n",
      "Epoch 154/300\n",
      "379/379 [==============================] - 0s - loss: 0.0193 - val_loss: 0.1830\n",
      "Epoch 155/300\n",
      "379/379 [==============================] - 0s - loss: 0.0185 - val_loss: 0.2664\n",
      "Epoch 156/300\n",
      "379/379 [==============================] - 0s - loss: 0.0201 - val_loss: 0.2564\n",
      "Epoch 157/300\n",
      "379/379 [==============================] - 0s - loss: 0.0218 - val_loss: 0.2360\n",
      "Epoch 158/300\n",
      "379/379 [==============================] - 0s - loss: 0.0161 - val_loss: 0.1874\n",
      "Epoch 159/300\n",
      "379/379 [==============================] - 0s - loss: 0.0176 - val_loss: 0.3341\n",
      "Epoch 160/300\n",
      "379/379 [==============================] - 0s - loss: 0.0596 - val_loss: 0.2673\n",
      "Epoch 161/300\n",
      "379/379 [==============================] - 0s - loss: 0.0164 - val_loss: 0.2330\n",
      "Epoch 162/300\n",
      "379/379 [==============================] - 0s - loss: 0.0162 - val_loss: 0.1300\n",
      "Epoch 163/300\n",
      "379/379 [==============================] - 0s - loss: 0.1208 - val_loss: 0.1755\n",
      "Epoch 164/300\n",
      "379/379 [==============================] - 0s - loss: 0.0413 - val_loss: 0.2948\n",
      "Epoch 165/300\n",
      "379/379 [==============================] - 0s - loss: 0.0227 - val_loss: 0.2531\n",
      "Epoch 166/300\n",
      "379/379 [==============================] - 0s - loss: 0.0160 - val_loss: 0.1870\n",
      "Epoch 167/300\n",
      "379/379 [==============================] - 0s - loss: 0.0947 - val_loss: 0.1788\n",
      "Epoch 168/300\n",
      "379/379 [==============================] - 0s - loss: 0.0522 - val_loss: 0.2662\n",
      "Epoch 169/300\n",
      "379/379 [==============================] - 0s - loss: 0.0133 - val_loss: 0.2965\n",
      "Epoch 170/300\n",
      "379/379 [==============================] - 0s - loss: 0.0233 - val_loss: 0.1649\n",
      "Epoch 171/300\n",
      "379/379 [==============================] - 0s - loss: 0.0501 - val_loss: 0.1684\n",
      "Epoch 172/300\n",
      "379/379 [==============================] - 0s - loss: 0.1802 - val_loss: 0.1575\n",
      "Epoch 173/300\n",
      "379/379 [==============================] - 0s - loss: 0.0895 - val_loss: 0.1829\n",
      "Epoch 174/300\n",
      "379/379 [==============================] - 0s - loss: 0.3291 - val_loss: 0.1278\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s - loss: 0.1395 - val_loss: 0.1874\n",
      "Epoch 176/300\n",
      "379/379 [==============================] - 0s - loss: 0.0184 - val_loss: 0.1996\n",
      "Epoch 177/300\n",
      "379/379 [==============================] - 0s - loss: 0.0156 - val_loss: 0.2246\n",
      "Epoch 178/300\n",
      "379/379 [==============================] - 0s - loss: 0.0158 - val_loss: 0.1642\n",
      "Epoch 179/300\n",
      "379/379 [==============================] - 0s - loss: 0.0222 - val_loss: 0.2388\n",
      "Epoch 180/300\n",
      "379/379 [==============================] - 0s - loss: 0.0199 - val_loss: 0.1865\n",
      "Epoch 181/300\n",
      "379/379 [==============================] - 0s - loss: 0.0231 - val_loss: 0.1558\n",
      "Epoch 182/300\n",
      "379/379 [==============================] - 0s - loss: 0.0949 - val_loss: 0.2191\n",
      "Epoch 183/300\n",
      "379/379 [==============================] - 0s - loss: 0.0330 - val_loss: 0.1805\n",
      "Epoch 184/300\n",
      "379/379 [==============================] - 0s - loss: 0.0526 - val_loss: 0.0952\n",
      "Epoch 185/300\n",
      "379/379 [==============================] - 0s - loss: 0.0831 - val_loss: 0.1585\n",
      "Epoch 186/300\n",
      "379/379 [==============================] - 0s - loss: 0.0192 - val_loss: 0.2467\n",
      "Epoch 187/300\n",
      "379/379 [==============================] - 0s - loss: 0.0142 - val_loss: 0.2497\n",
      "Epoch 188/300\n",
      "379/379 [==============================] - 0s - loss: 0.0352 - val_loss: 0.2208\n",
      "Epoch 189/300\n",
      "379/379 [==============================] - 0s - loss: 0.0133 - val_loss: 0.1837\n",
      "Epoch 190/300\n",
      "379/379 [==============================] - 0s - loss: 0.0156 - val_loss: 0.2209\n",
      "Epoch 191/300\n",
      "379/379 [==============================] - 0s - loss: 0.0122 - val_loss: 0.2138\n",
      "Epoch 192/300\n",
      "379/379 [==============================] - 0s - loss: 0.0109 - val_loss: 0.2029\n",
      "Epoch 193/300\n",
      "379/379 [==============================] - 0s - loss: 0.0215 - val_loss: 0.2431\n",
      "Epoch 194/300\n",
      "379/379 [==============================] - 0s - loss: 0.0130 - val_loss: 0.1981\n",
      "Epoch 195/300\n",
      "379/379 [==============================] - 0s - loss: 0.0109 - val_loss: 0.2103\n",
      "Epoch 196/300\n",
      "379/379 [==============================] - 0s - loss: 0.0107 - val_loss: 0.2542\n",
      "Epoch 197/300\n",
      "379/379 [==============================] - 0s - loss: 0.0194 - val_loss: 0.3550\n",
      "Epoch 198/300\n",
      "379/379 [==============================] - 0s - loss: 0.0695 - val_loss: 0.2295\n",
      "Epoch 199/300\n",
      "379/379 [==============================] - 0s - loss: 0.0283 - val_loss: 0.1904\n",
      "Epoch 200/300\n",
      "379/379 [==============================] - 0s - loss: 0.0189 - val_loss: 0.1848\n",
      "Epoch 201/300\n",
      "379/379 [==============================] - 0s - loss: 0.0135 - val_loss: 0.1850\n",
      "Epoch 202/300\n",
      "379/379 [==============================] - 0s - loss: 0.0187 - val_loss: 0.2073\n",
      "Epoch 203/300\n",
      "379/379 [==============================] - 0s - loss: 0.0268 - val_loss: 0.2410\n",
      "Epoch 204/300\n",
      "379/379 [==============================] - 0s - loss: 0.0405 - val_loss: 0.2326\n",
      "Epoch 205/300\n",
      "379/379 [==============================] - 0s - loss: 0.0641 - val_loss: 0.3187\n",
      "Epoch 206/300\n",
      "379/379 [==============================] - 0s - loss: 0.0357 - val_loss: 0.2307\n",
      "Epoch 207/300\n",
      "379/379 [==============================] - 0s - loss: 0.0094 - val_loss: 0.2519\n",
      "Epoch 208/300\n",
      "379/379 [==============================] - 0s - loss: 0.0268 - val_loss: 0.1937\n",
      "Epoch 209/300\n",
      "379/379 [==============================] - 0s - loss: 0.0350 - val_loss: 0.2011\n",
      "Epoch 210/300\n",
      "379/379 [==============================] - 0s - loss: 0.0151 - val_loss: 0.2566\n",
      "Epoch 211/300\n",
      "379/379 [==============================] - 0s - loss: 0.0109 - val_loss: 0.2137\n",
      "Epoch 212/300\n",
      "379/379 [==============================] - 0s - loss: 0.0171 - val_loss: 0.2021\n",
      "Epoch 213/300\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.006 - 0s - loss: 0.0144 - val_loss: 0.2653\n",
      "Epoch 214/300\n",
      "379/379 [==============================] - 0s - loss: 0.0101 - val_loss: 0.2375\n",
      "Epoch 215/300\n",
      "379/379 [==============================] - 0s - loss: 0.0173 - val_loss: 0.3642\n",
      "Epoch 216/300\n",
      "379/379 [==============================] - 0s - loss: 0.0400 - val_loss: 0.2514\n",
      "Epoch 217/300\n",
      "379/379 [==============================] - 0s - loss: 0.0152 - val_loss: 0.2448\n",
      "Epoch 218/300\n",
      "379/379 [==============================] - 0s - loss: 0.0124 - val_loss: 0.2924\n",
      "Epoch 219/300\n",
      "379/379 [==============================] - 0s - loss: 0.0619 - val_loss: 0.3401\n",
      "Epoch 220/300\n",
      "379/379 [==============================] - 0s - loss: 0.0652 - val_loss: 0.2829\n",
      "Epoch 221/300\n",
      "379/379 [==============================] - 0s - loss: 0.0199 - val_loss: 0.3424\n",
      "Epoch 222/300\n",
      "379/379 [==============================] - 0s - loss: 0.0719 - val_loss: 0.5088\n",
      "Epoch 223/300\n",
      "379/379 [==============================] - 0s - loss: 0.0370 - val_loss: 0.2480\n",
      "Epoch 224/300\n",
      "379/379 [==============================] - 0s - loss: 0.0165 - val_loss: 0.2878\n",
      "Epoch 225/300\n",
      "379/379 [==============================] - 0s - loss: 0.0220 - val_loss: 0.2736\n",
      "Epoch 226/300\n",
      "379/379 [==============================] - 0s - loss: 0.0289 - val_loss: 0.2717\n",
      "Epoch 227/300\n",
      "379/379 [==============================] - 0s - loss: 0.0154 - val_loss: 0.2039\n",
      "Epoch 228/300\n",
      "379/379 [==============================] - 0s - loss: 0.0093 - val_loss: 0.2167\n",
      "Epoch 229/300\n",
      "379/379 [==============================] - 0s - loss: 0.0081 - val_loss: 0.2332\n",
      "Epoch 230/300\n",
      "379/379 [==============================] - 0s - loss: 0.0097 - val_loss: 0.1523\n",
      "Epoch 231/300\n",
      "379/379 [==============================] - 0s - loss: 0.0413 - val_loss: 0.1109\n",
      "Epoch 232/300\n",
      "379/379 [==============================] - 0s - loss: 0.0272 - val_loss: 0.2462\n",
      "Epoch 233/300\n",
      "379/379 [==============================] - 0s - loss: 0.0111 - val_loss: 0.2706\n",
      "Epoch 234/300\n",
      "379/379 [==============================] - 0s - loss: 0.0347 - val_loss: 0.2462\n",
      "Epoch 235/300\n",
      "379/379 [==============================] - 0s - loss: 0.0094 - val_loss: 0.2403\n",
      "Epoch 236/300\n",
      "379/379 [==============================] - 0s - loss: 0.0143 - val_loss: 0.2144\n",
      "Epoch 237/300\n",
      "379/379 [==============================] - 0s - loss: 0.0105 - val_loss: 0.2242\n",
      "Epoch 238/300\n",
      "379/379 [==============================] - 0s - loss: 0.0081 - val_loss: 0.2364\n",
      "Epoch 239/300\n",
      "379/379 [==============================] - 0s - loss: 0.0085 - val_loss: 0.2138\n",
      "Epoch 240/300\n",
      "379/379 [==============================] - 0s - loss: 0.0247 - val_loss: 0.2367\n",
      "Epoch 241/300\n",
      "379/379 [==============================] - 0s - loss: 0.0232 - val_loss: 0.1730\n",
      "Epoch 242/300\n",
      "379/379 [==============================] - 0s - loss: 0.0090 - val_loss: 0.2116\n",
      "Epoch 243/300\n",
      "379/379 [==============================] - 0s - loss: 0.0534 - val_loss: 0.2127\n",
      "Epoch 244/300\n",
      "379/379 [==============================] - 0s - loss: 0.0122 - val_loss: 0.2196\n",
      "Epoch 245/300\n",
      "379/379 [==============================] - 0s - loss: 0.0132 - val_loss: 0.2055\n",
      "Epoch 246/300\n",
      "379/379 [==============================] - 0s - loss: 0.0082 - val_loss: 0.2175\n",
      "Epoch 247/300\n",
      "379/379 [==============================] - 0s - loss: 0.0129 - val_loss: 0.2289\n",
      "Epoch 248/300\n",
      "379/379 [==============================] - 0s - loss: 0.0109 - val_loss: 0.2198\n",
      "Epoch 249/300\n",
      "379/379 [==============================] - 0s - loss: 0.0266 - val_loss: 0.2175\n",
      "Epoch 250/300\n",
      "379/379 [==============================] - 0s - loss: 0.0501 - val_loss: 0.1632\n",
      "Epoch 251/300\n",
      "379/379 [==============================] - 0s - loss: 0.0308 - val_loss: 0.2534\n",
      "Epoch 252/300\n",
      "379/379 [==============================] - 0s - loss: 0.0380 - val_loss: 0.3246\n",
      "Epoch 253/300\n",
      "379/379 [==============================] - 0s - loss: 0.0177 - val_loss: 0.2334\n",
      "Epoch 254/300\n",
      "379/379 [==============================] - 0s - loss: 0.0106 - val_loss: 0.2495\n",
      "Epoch 255/300\n",
      "379/379 [==============================] - 0s - loss: 0.0074 - val_loss: 0.2364\n",
      "Epoch 256/300\n",
      "379/379 [==============================] - 0s - loss: 0.0082 - val_loss: 0.2565\n",
      "Epoch 257/300\n",
      "379/379 [==============================] - 0s - loss: 0.0107 - val_loss: 0.2174\n",
      "Epoch 258/300\n",
      "379/379 [==============================] - 0s - loss: 0.0289 - val_loss: 0.4454\n",
      "Epoch 259/300\n",
      "379/379 [==============================] - 0s - loss: 0.0476 - val_loss: 0.3241\n",
      "Epoch 260/300\n",
      "379/379 [==============================] - 0s - loss: 0.0575 - val_loss: 0.2532\n",
      "Epoch 261/300\n",
      "379/379 [==============================] - 0s - loss: 0.0093 - val_loss: 0.1717\n",
      "Epoch 262/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s - loss: 0.0075 - val_loss: 0.2327\n",
      "Epoch 263/300\n",
      "379/379 [==============================] - 0s - loss: 0.0167 - val_loss: 0.3862\n",
      "Epoch 264/300\n",
      "379/379 [==============================] - 0s - loss: 0.0846 - val_loss: 0.3941\n",
      "Epoch 265/300\n",
      "379/379 [==============================] - 0s - loss: 0.0239 - val_loss: 0.2340\n",
      "Epoch 266/300\n",
      "379/379 [==============================] - 0s - loss: 0.0073 - val_loss: 0.1796\n",
      "Epoch 267/300\n",
      "379/379 [==============================] - 0s - loss: 0.0105 - val_loss: 0.2775\n",
      "Epoch 268/300\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.015 - 0s - loss: 0.0163 - val_loss: 0.3497\n",
      "Epoch 269/300\n",
      "379/379 [==============================] - 0s - loss: 0.0663 - val_loss: 0.4926\n",
      "Epoch 270/300\n",
      "379/379 [==============================] - 0s - loss: 0.2971 - val_loss: 0.3389\n",
      "Epoch 271/300\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.054 - 0s - loss: 0.0311 - val_loss: 0.2699\n",
      "Epoch 272/300\n",
      "379/379 [==============================] - 0s - loss: 0.0355 - val_loss: 0.3155\n",
      "Epoch 273/300\n",
      "379/379 [==============================] - 0s - loss: 0.0418 - val_loss: 0.2178\n",
      "Epoch 274/300\n",
      "379/379 [==============================] - 0s - loss: 0.0076 - val_loss: 0.2485\n",
      "Epoch 275/300\n",
      "379/379 [==============================] - 0s - loss: 0.0128 - val_loss: 0.2159\n",
      "Epoch 276/300\n",
      "379/379 [==============================] - 0s - loss: 0.0084 - val_loss: 0.2286\n",
      "Epoch 277/300\n",
      "379/379 [==============================] - 0s - loss: 0.0079 - val_loss: 0.2059\n",
      "Epoch 278/300\n",
      "379/379 [==============================] - 0s - loss: 0.0070 - val_loss: 0.2270\n",
      "Epoch 279/300\n",
      "379/379 [==============================] - 0s - loss: 0.0083 - val_loss: 0.1828\n",
      "Epoch 280/300\n",
      "379/379 [==============================] - 0s - loss: 0.0122 - val_loss: 0.2306\n",
      "Epoch 281/300\n",
      "379/379 [==============================] - 0s - loss: 0.0062 - val_loss: 0.2033\n",
      "Epoch 282/300\n",
      "379/379 [==============================] - 0s - loss: 0.0065 - val_loss: 0.2585\n",
      "Epoch 283/300\n",
      "379/379 [==============================] - 0s - loss: 0.0069 - val_loss: 0.1953\n",
      "Epoch 284/300\n",
      "379/379 [==============================] - 0s - loss: 0.0092 - val_loss: 0.2777\n",
      "Epoch 285/300\n",
      "379/379 [==============================] - 0s - loss: 0.0191 - val_loss: 0.2146\n",
      "Epoch 286/300\n",
      "379/379 [==============================] - 0s - loss: 0.0098 - val_loss: 0.1722\n",
      "Epoch 287/300\n",
      "379/379 [==============================] - 0s - loss: 0.0121 - val_loss: 0.2231\n",
      "Epoch 288/300\n",
      "379/379 [==============================] - 0s - loss: 0.0268 - val_loss: 0.2436\n",
      "Epoch 289/300\n",
      "379/379 [==============================] - 0s - loss: 0.0092 - val_loss: 0.2474\n",
      "Epoch 290/300\n",
      "379/379 [==============================] - 0s - loss: 0.0156 - val_loss: 0.2323\n",
      "Epoch 291/300\n",
      "379/379 [==============================] - 0s - loss: 0.0173 - val_loss: 0.2034\n",
      "Epoch 292/300\n",
      "379/379 [==============================] - 0s - loss: 0.0153 - val_loss: 0.2459\n",
      "Epoch 293/300\n",
      "379/379 [==============================] - 0s - loss: 0.0081 - val_loss: 0.2410\n",
      "Epoch 294/300\n",
      "379/379 [==============================] - 0s - loss: 0.0074 - val_loss: 0.1969\n",
      "Epoch 295/300\n",
      "379/379 [==============================] - 0s - loss: 0.0126 - val_loss: 0.3087\n",
      "Epoch 296/300\n",
      "379/379 [==============================] - 0s - loss: 0.0965 - val_loss: 0.2291\n",
      "Epoch 297/300\n",
      "379/379 [==============================] - 0s - loss: 0.0067 - val_loss: 0.1886\n",
      "Epoch 298/300\n",
      "379/379 [==============================] - 0s - loss: 0.0086 - val_loss: 0.1286\n",
      "Epoch 299/300\n",
      "379/379 [==============================] - 0s - loss: 0.0225 - val_loss: 0.1367\n",
      "Epoch 300/300\n",
      "379/379 [==============================] - 0s - loss: 0.0136 - val_loss: 0.1887\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=X_train_scaled.shape[1], init='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, init='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,loss='mean_squared_error')\n",
    "\n",
    "hist = model.fit(X_train_scaled.as_matrix(), y_train.as_matrix(), nb_epoch=300,\n",
    "verbose=1, validation_data=(X_test_scaled.as_matrix(), y_test.as_matrix()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) repetir (c) y (d) variando tasa de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_lr = 20\n",
    "lear_rate = np.linspace(0,1,n_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-66-0257b4651046>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-0257b4651046>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    model = Sequential()\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "Xm = X_train_scaled.as_matrix()\n",
    "ym = y_train_scaled.as_matrix()\n",
    "kfold = cross_validation.KFold(len(Xm), 10)\n",
    "cvscores = []\n",
    "for i, (train, val) in enumerate(kfold):\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=Xm.shape[1], init='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, init='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "# Compile model\n",
    "sgd = SGD(lr=0.2)\n",
    "model.compile(optimizer=sgd,loss='mean_squared_error')\n",
    "# Fit the model\n",
    "model.fit(Xm[train], ym[train], nb_epoch=300)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(Xm[val], ym[val])\n",
    "cvscores.append(scores)\n",
    "mse_cv = np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_decay = 10\n",
    "lear_decay = np.logspace(-6,0,n_decay)\n",
    "sgd = SGD(lr=0.2, decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_decay = 21\n",
    "momentum = np.linspace(0,1,n_decay)\n",
    "sgd = SGD(lr=0.2,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))\n",
    "model.fit(X_train_scaled.as_matrix(),y_train_scaled.as_matrix(),batch_size=50,nb_epoch=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "model.compile(optimizer=moptimizer)\n",
    "model.fit(X_train_scaled.as_matrix(),y_train_scaled.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#la regularization se debe incorporar a cada capa separadamente\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(200,input_dim=idim,init='uniform',W_regularizer=l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, init='uniform',W_regularizer=l2(0.01)))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2))\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(200,input_dim=idim,init='uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, init='uniform'))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
